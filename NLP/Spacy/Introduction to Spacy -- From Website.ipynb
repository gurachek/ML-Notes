{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Spacy\n",
    "\n",
    "## Everything you Need to Know about Spacy\n",
    "\n",
    "https://spacy.io/usage/spacy-101\n",
    "\n",
    "\n",
    "Spacy uses neural network models, trained on classical NLP datasets, to predict the NLP data of a sentence. There are different model that vary for different use cases. Some are larger and more accurate, some trained on different kinds of data, some predict different things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy Features\n",
    "\n",
    "- Tokenization -- Segmenting your text. \n",
    "- Parts- of Speech Tagging -- Assigning grammatical word types to individual words in a sentence.\n",
    "- Dependency Parsing -- Assigning dependency labels that describe relationships between tokens.\n",
    "- Lemmatization -- Assigning the base form of a word\n",
    "- Sentenc Boundary Detection -- Finding and Segmenting individual sentences.\n",
    "- Named Entity Recoginition -- Label real world objects.\n",
    "- Similarity -- comparing two textual documents to determine similarity.\n",
    "- Text Classification -- Assigning categories and labels to a document or subdocument.\n",
    "- Rule Based Matching -- regex\n",
    "- Training -- Statistical model predictions?\n",
    "- Serialization -- Saving objects to files or bite strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English Models\n",
    "Downloadable statistical models for spaCy to predict and assign features. Most are CNNs with residual connections, layer normalization, and maxout nonlinearity.\n",
    "\n",
    "- tagging\n",
    "- parsing\n",
    "- entity recognition\n",
    "\n",
    "#### en_core_web_sm\n",
    "English multitask CNN assigns content specific token vectors, Parts of Speech tags, depencdency parsing, and Named Entities. 29MB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is Harrison and I do not likely Apple Music.\n",
      "My ADJ poss\n",
      "name NOUN nsubj\n",
      "is VERB ROOT\n",
      "Harrison PROPN attr\n",
      "and CCONJ cc\n",
      "I PRON nsubj\n",
      "do VERB aux\n",
      "not ADV neg\n",
      "likely ADV conj\n",
      "Apple PROPN compound\n",
      "Music PROPN dobj\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# load the model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "#assign avariable with the models output.\n",
    "doc = nlp(\"My name is Harrison and I do not likely Apple Music.\")\n",
    "print(doc.text)\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linguistic Annotation \n",
    "\n",
    "load a model with spacy.load(). Which returns a language model that is referred to as nlp. Call nlp on a doc to return a compressed doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sometimes ADV advmod\n",
      "I PRON nsubj\n",
      "cry VERB ROOT\n",
      "myself PRON dobj\n",
      "to PART aux\n",
      "sleep VERB ccomp\n",
      "at ADP prep\n",
      "night NOUN pobj\n",
      "thinking VERB advcl\n",
      "about ADP prep\n",
      "Donald PROPN compound\n",
      "Trump PROPN pobj\n",
      "and CCONJ cc\n",
      "Brexit PROPN conj\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Sometimes I cry myself to sleep at night thinking about Donald Trump and Brexit.\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "Each document is tokenized by rules specific to each language.\n",
    "Raw text is split on whitespace, then the tokenizer iterates over the text.\n",
    "\n",
    "Checks:\n",
    "1. Does the substring match a tokenizer exception?\n",
    "2. Can a prefix, suffix, or infix be split off?\n",
    "\n",
    "Prefix: Character(s) at the beginning, e.g. $, (, “, ¿.\n",
    "\n",
    "Suffix: Character(s) at the end, e.g. km, ), ”, !.\n",
    "\n",
    "Infix: Character(s) in between, e.g. -, --, /, ….\n",
    "\n",
    "If the substring matches to an above exception, the substring is modified and the tokenizer continues its iteration through the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chimpanzees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sunshine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Text\n",
       "0  Chimpanzees\n",
       "1        drink\n",
       "2         boba\n",
       "3            -\n",
       "4          tea\n",
       "5           in\n",
       "6          the\n",
       "7     sunshine\n",
       "8            ."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "doc = nlp(\"Chimpanzees drink boba-tea in the sunshine.\")\n",
    "df = pd.DataFrame([token.text for token in doc], columns = [\"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parts-of-Speech tags and Dependencies\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
