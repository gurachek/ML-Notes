{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0                    top 3 all   tablets  damn right! \n",
      "1    cnbctv   apple's margins better than expected?...\n",
      "2    wtf my battery was 31  one second ago and now ...\n",
      "3    rt  bought my  at the  store  pretty good logo...\n",
      "4     contact sync between yosemite and ios8 is ser...\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"C://Users//Harrison//Desktop//APT\")\n",
    "\n",
    "X_train = pd.read_csv('train_clean.csv', header = None, index_col = 0)[1]\n",
    "X_test = pd.read_csv('test_clean.csv', header = None, index_col = 0)[1]\n",
    "y_train = pd.read_csv('y_train.csv', header = None, index_col = 0)[1]\n",
    "y_test = pd.read_csv('y_test.csv', header = None, index_col = 0)[1]\n",
    "print(X_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "X_train = tfidf.fit_transform(X_train)\n",
    "X_test = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harrison\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy:  0.7264437689969605\n",
      "\n",
      "Logistic Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.88      0.82       226\n",
      "          1       0.60      0.39      0.47       103\n",
      "\n",
      "avg / total       0.71      0.73      0.71       329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logr = LogisticRegressionCV(class_weight = 'balanced')\n",
    "logr.fit(X_train, y_train)\n",
    "y_pred_logr = logr.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "#Logistic Regression Eval\n",
    "print('Logistic Regression Accuracy: ', accuracy_score(y_test, y_pred_logr))\n",
    "print('\\nLogistic Classification Report: \\n' , classification_report(y_test,  y_pred_logr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 3701\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Embedding(max_features, output_dim = 256))\n",
    "model.add(keras.layers.LSTM(128))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(1, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "             optimizer = 'rmsprop',\n",
    "             metrics = ['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size = 16, epochs = 2)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3387351],\n",
       "       [0.3387351],\n",
       "       [0.3387351],\n",
       "       [0.3387351],\n",
       "       [0.3387351],\n",
       "       [0.3387351],\n",
       "       [0.3387351],\n",
       "       [0.3387351],\n",
       "       [0.3387351],\n",
       "       [0.3387351]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D ConvNet (To Do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, Dense, Dropout, Embedding, MaxPooling1D, GlobalAveragePooling1D\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "seq_length = 3245\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(64, 3, activation='relu', input_shape=(seq_length, 100)))\n",
    "model.add(Conv1D(64, 3, activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=16, epochs=10)\n",
    "score = model.evaluate(x_test, y_test, batch_size=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
