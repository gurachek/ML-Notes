{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection \n",
    "\n",
    "https://machinelearningmastery.com/an-introduction-to-feature-selection/\n",
    "\n",
    "The process of choosing the features that would most benefit your predictive model without adding too much complexity.\n",
    "\n",
    "Different from dimensionality reduction which seeks to reduce the number of features by mathematical decompoition of the feature space. Feature selection simply excludes entire dimensions from a potential feature space.\n",
    "\n",
    "Feature selection can potentially boost accuracy (curse of dimensionality) while reducing processing/training time. A simpler model is also easier to explain come evaluation time.\n",
    "\n",
    "\n",
    "## Feature Selection Algorithms\n",
    "\n",
    "### Filter Methods\n",
    "\n",
    "Filter selection methods apply statistical measures to each feature in an attempt to create a scoring for each feature. Features are then ranked and included in a somewhat greedy approach. These methods are univariate and consider each feature independently without regard to interralation effects between features.\n",
    "\n",
    "Chi Squared Test, Information Gain, and Correlation Coefficient Scores.\n",
    "\n",
    "\n",
    "### Wrapper Methods\n",
    "\n",
    "Different combinations are prepared evaluated, and compared to other combinations. In this case a predictive model might be used to fit on certain combinations and provide a score based on model accuracy.\n",
    "\n",
    "May be methodical (best-fit search), stochastic (random hill climb), or heuristic (forward and backward passes to add and remove features)\n",
    "\n",
    "\n",
    "\n",
    "### Embedded Methods\n",
    " Learn which features contribute most to model accuracy during the fitting stage. Most commonly regularization methods. (L1 Regularization) Drive down coefficients of less useful features to create a sparse weight matrix. Biases the model towards lower commplexity\n",
    " \n",
    " LASSO, Elastic Net.\n",
    " \n",
    " \n",
    " # Feature Selection Pitfalls\n",
    " \n",
    " Feature selection is a part of the model selection process. Do Feature selection on a different dataset that you train on, otherwise risk overfitting by selecting the features that overfit the data you are working on.\n",
    " \n",
    " https://stats.stackexchange.com/questions/40576/is-using-the-same-data-for-feature-selection-and-cross-validation-biased-or-not\n",
    " \n",
    " #### Do Feature Selection on a different dataset than you train on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
